# Software Requirements Specification (SRS) for AWS-CapacityForecaster

## 1. Introduction
- **Purpose**: This document defines the functional and non-functional requirements for AWS-CapacityForecaster, a cloud-native system for forecasting enterprise server resource utilization, identifying capacity risks, and recommending optimizations. It recreates enterprise capacity planning workflows inspired by 8 years at Citi Financial.
- **Scope**: The system will process synthetic/historical monitoring data, apply ML models for time-series forecasting, perform risk analysis, and generate reports/dashboards. It integrates AWS services (S3, SageMaker, Athena) for data storage, ML training, and querying.
- **References**: Citi experience doc (citi.md), Project planning (00001.Project1_planning.md), AWS integration (00002.aws_added_To_Project1.md).

## 2. Overall Description
- **Product Perspective**: Simulates Citi-style pipelines for proactive infrastructure management, focusing on cost savings and performance SLAs.
- **Product Functions**: Data ingestion/ETL, ML forecasting (3-6 months ahead), seasonal risk flagging, underutilization detection via clustering, visualizations, and AWS-automated workflows.
- **User Classes**: Data Engineers (build/maintain), Capacity Planners (use forecasts/reports), Executives (view dashboards).
- **Assumptions/Dependencies**: Python 3.10+, AWS account with $200 credits; no real-time production integration.

## 3. Functional Requirements
Break into modules with user stories.

### 3.1 Data Generation & Ingestion
- FR1.1: Generate synthetic time-series data for 100+ servers (CPU/mem/disk P95 metrics, daily granularity, 3+ years) using pandas/numpy, including seasonal peaks (e.g., end-of-quarter).
- User Story: As a data engineer, I want to upload generated CSVs to S3 via boto3 so that data is stored cost-effectively.

### 3.2 ETL Pipeline
- FR2.1: Cleanse data (handle missing values, outliers via scikit-learn imputation, z-score filtering with scipy).
- FR2.2: Feature engineering (lags, rolling averages, external regressors like "banking holiday flag") using pandas.
- FR2.3: Query processed data with Athena (SQL on S3) to simulate Oracle backup DB access.
- User Story: As a capacity planner, I want automated ETL in SageMaker Processing Jobs so that data is ready for ML without manual intervention.

### 3.3 ML Forecasting
- FR3.1: Train/compare models: Prophet (seasonality), scikit-learn RandomForest/GradientBoosting, optional Amazon Forecast.
- FR3.2: Evaluate with metrics (MAE, RMSE) and statsmodels tests (ADF for stationarity).
- FR3.3: Forecast 3-6 months ahead, parallelized with joblib.
- User Story: As a capacity planner, I want accurate forecasts (>20% better than baseline) so that I can plan upgrades proactively.

### 3.4 Risk Analysis & Optimization
- FR4.1: Flag at-risk servers (P95 > 80% during peaks) using scipy percentiles.
- FR4.2: Cluster utilization patterns (K-Means in scikit-learn) to detect underutilized resources and recommend consolidations/cost savings.
- User Story: As an executive, I want optimization reports showing potential savings (>10% resource reduction) so that I can justify budgets.

### 3.5 Visualization & Reporting
- FR5.1: Generate interactive plots (trends, forecasts vs actual) with plotly/matplotlib/seaborn.
- FR5.2: Build dashboards in QuickSight or Dash app.
- FR5.3: Export reports to PDF/Excel via openpyxl/reportlab.
- User Story: As a user, I want monthly/seasonal reports so that I can review utilization and risks.

### 3.6 Automation (Optional)
- FR6.1: Schedule pipelines via Lambda/EventBridge.

## 4. Non-Functional Requirements
- **Performance**: Process 100k+ rows in <5 min (local/SageMaker); forecasts in <1 min.
- **Scalability**: Handle up to 1M rows with AWS serverless.
- **Security**: Use IAM least-privilege; no sensitive data.
- **Usability**: CLI/notebook interface; clear README.
- **Reliability**: Model accuracy >85%; error handling in code.
- **Maintainability**: PEP8 standards, comments, unit tests.

## 5. Supporting Information
- **Glossary**: Define terms (e.g., P95: 95th percentile metric).
- **Appendices**: Sample data schema, acceptance criteria (e.g., "Forecast MAE <5% on test data").

Version: 1.0 | Date: January 18, 2026 | Author: Sean Girgis