# Specification Kit: 004 - SageMaker Canvas Integration Strategy

**Spec Kit Version:** 1.0  
**Date:** January 31, 2026  
**Author:** Grok (assisted draft based on repo analysis and project continuity)  
**Status:** Draft - Ready for Review & Implementation  
**Related Specs:**  
- Spec 001: Overall Project Architecture (inferred; formalize in future)  
- Spec 002: SageMaker Dry Run for Module 04 (completed)  
- Spec 003: SageMaker Processing for Module 05 (completed)  
**GitHub Issue Link:** [Create a new issue on https://github.com/seanlgirgis/AWS-CapacityForecaster/issues with this spec content]  

---

## 1. Objective
This specification outlines the strategy to integrate Amazon SageMaker Canvas as a managed, low-code forecasting approach in the AWS-CapacityForecaster project. As the "third model" path (replacing Amazon Forecast, which is unavailable for new AWS accounts since July 2024), Canvas provides auto-ML time-series forecasting with quantile outputs (p10/p50/p90) for uncertainty-aware predictions. This enhances the project's ML depth without heavy custom code, while maintaining hybrid execution (local + cloud).

Integration focuses on Module 04 (Model Training & Forecasting) for generating Canvas-based forecasts, with optional use in Module 05 (Risk & Capacity Analysis) for risk enhancement (e.g., p90 bounds for high-risk flagging). This aligns with priorities:  
- **Priority 1: Data Science/ML** - Adds auto-ML comparison to custom models (Prophet/RF), improving accuracy metrics (e.g., sMAPE on quantiles).  
- **Priority 2: Capacity Planning/Performance** - Enables conservative risk analysis using Canvas's uncertainty intervals.  
- **Priority 3: Python + AWS Skills** - Demonstrates boto3/SageMaker API for Canvas job orchestration, S3 data flow.

**Expected Outcomes:**  
- Canvas forecasts as alternative outputs in Module 04 (Parquet with quantiles).  
- Comparison metrics vs. custom models.  
- Low-cost execution (~$0.10-0.20 per small training job).  
- Updated repo readiness (code checked in; GitHub shows partial SageMaker setup via .sagemakerignore and jobs URL).

**Repo Status Check (from GitHub Analysis):**  
- Structure: Modular pipeline (src/modules up to 04; no explicit 05 visible, but inferred from progress_docs). Config-driven (config/config.yaml).  
- SageMaker Integration: Partial—artifacts like .sagemakerignore and SageMaker_jobs.url exist; code in src/modules (e.g., module_04_model_training.py) is ready for extension, but no direct Canvas/Forecast mentions yet.  
- Readiness: Code checked in (70 commits on main); active development (recent Jan 2026 updates). No open issues; add Canvas via new utility in src/utils. Modules 04/05 runnable locally; extend to cloud.  

## 2. Requirements Phase
### Functional Requirements  
- **FR-04C.1:** Export processed features from Module 03 to S3 (CSV format for Canvas import).  
- **FR-04C.2:** Trigger Canvas time-series forecasting via boto3/SageMaker API or Studio UI (initially manual for testing).  
- **FR-04C.3:** Train on server metrics (e.g., target: cpu_p95; timestamp/item_id: server_id). Generate 90-day horizon forecasts with p10/p50/p90.  
- **FR-04C.4:** Export Canvas results to S3 (CSV/Parquet); merge into Module 04 outputs for comparison (e.g., sMAPE vs. Prophet).  
- **FR-04C.5:** Optional: In Module 05, use Canvas p90 for risk thresholds (e.g., if p90 > 90% → high risk).  
- **FR-04C.6:** Log job status/costs; fallback to custom models if Canvas unavailable.

### Non-Functional Requirements  
- **NFR-04C.1:** Cost: Use small datasets (~100 servers); limit training to <30 min (~$0.10-0.20).  
- **NFR-04C.2:** Security: Use existing IAM role (sagemaker_role_arn from config.yaml); S3 least privilege.  
- **NFR-04C.3:** Performance: Handle 3-year daily data per server; auto-ML handles scaling.  
- **NFR-04C.4:** Reliability: Error handling for API calls (boto3 retries); local mock for testing.  
- **NFR-04C.5:** Compatibility: Reuse sagemaker_launcher.py for data upload; support local fallback via notebooks/.  
- **NFR-04C.6:** Documentation: Update README.md with Canvas setup; create progress report.

### User Stories  
- As a developer, I want to run Canvas forecasting in Module 04 so that I can compare managed auto-ML to custom models.  
- As a portfolio viewer, I want to see SageMaker Canvas integration to demonstrate low-code AWS ML skills.

### Assumptions & Dependencies  
- AWS account has SageMaker Studio domain (free-tier eligible).  
- Config.yaml has valid aws.region, bucket_name, sagemaker_role_arn.  
- Modules 01-03 outputs exist (processed features in S3/local).  
- boto3 session uses profile from config (local) or IAM role (cloud).  
- No Amazon Forecast (sunset); Canvas is the managed pivot.

## 3. Design Phase
### System Architecture Updates  
- **High-Level Flow:** Module 03 (features) → S3 export → Canvas (train/forecast) → S3 results → Merge into Module 04 outputs → Module 05 risks.  
- **Data Flow:**  
  - Input: S3://{bucket}/processed/ (CSV: item_id=server_id, timestamp, target_value=cpu_p95 + regressors).  
  - Canvas: UI or boto3 (create_model, start_training).  
  - Output: S3://{bucket}/forecasts/canvas_forecasts.csv → Parquet conversion in code.  
- **Environment:** SageMaker Studio for initial UI testing; boto3 for automation (SageMaker Canvas APIs).  
- **Canvas Config:** Forecast frequency='D'; horizon=90; include related time series (e.g., holidays/EOQ as metadata if supported).

### Database/Storage Schema  
- Canvas Input CSV: Columns - item_id (str), timestamp (YYYY-MM-DD), target_value (float), optional regressors (e.g., is_eoq).  
- Output: Add to forecasts Parquet (model='canvas', p10/p50/p90).

### UI/UX Considerations  
- Canvas UI for manual runs (drag-drop S3 data); code for automation.

## 4. Implementation Phase
### Code Changes  
1. **src/utils/sagemaker_canvas.py** (New):  
   - Class `SageMakerCanvasRunner`: boto3 methods for create_dataset (from S3), train_model, generate_forecast, export_results.  
   - Fallback: Manual UI instructions in docstring.  
   - Example: `client = boto3.client('sagemaker'); response = client.create_auto_ml_job(...)` (adapt for Canvas APIs).  

2. **src/modules/module_04_model_training.py** (Update):  
   - Conditional: if config['ml']['models'][3]['enabled'] and type='canvas': Call SageMakerCanvasRunner.run_forecast().  
   - Merge Canvas results into all_forecasts; compute comparison metrics.  

3. **src/modules/module_05_risk_capacity_analysis.py** (Optional Update):  
   - Use Canvas p90: `df['risk_high'] = (df['p90'] > config['risk_analysis']['high_risk_threshold'])`.  

4. **module_00_pipeline_runner.py** (Minor):  
   - Add flag for canvas mode in --env sagemaker.  

5. **config/config.yaml**:  
   - Add ml.models[3]: {name: 'SageMakerCanvas', enabled: false, params: {horizon: 90}}.  

6. **notebooks/canvas_demo.ipynb** (New in notebooks/):  
   - Quick UI test script.  

### Development Steps  
1. Local Prep (C:\pyproj\AWS-CapacityForecaster): Run full local pipeline to generate inputs: `python src\modules\module_00_pipeline_runner.py --env local` (assumes modules up to 04; extend to 05 if ready).  
2. Upload Data: Use existing sagemaker_launcher.py or manual: `aws s3 cp data/processed/ s3://{bucket}/processed/ --recursive`.  
3. Canvas UI Test (AWS Console): SageMaker > Canvas > Create model > Time series > Import S3 data > Train > Export forecasts to S3.  
4. Automate: Implement sagemaker_canvas.py; test via `python src\modules\module_04_model_training.py --env sagemaker`.  
5. Run Modules 04/05 with Canvas: `python src\modules\module_00_pipeline_runner.py --env sagemaker --only 04 05` (after enabling in config).  
6. Commit: From C:\pyproj\AWS-CapacityForecaster: `git add .; git commit -m "Implement Spec 004: SageMaker Canvas Integration"; git push`.  

## 5. Testing & QA Phase
### Test Plan  
- **Unit Tests:** Add to sagemaker_canvas.py (e.g., pytest for API mocks).  
- **Integration Tests:** End-to-end: Local run → S3 upload → Canvas forecast → Compare to custom models.  
- **Traceability Matrix (RTM):**  
  | Requirement | Test Case |  
  |-------------|-----------|  
  | FR-04C.3   | Validate p50 forecast accuracy (sMAPE < 10%). |  
  | NFR-04C.1  | Monitor job cost in AWS Billing. |  

- **Edge Cases:** Small dataset; API rate limits; no regressors.

## 6. Deployment & Maintenance
### Deployment Checklist  
1. Verify AWS setup (Studio domain, role).  
2. Run local baseline.  
3. Execute cloud with Canvas enabled.  
4. Cleanup: Delete Canvas models; empty S3 test prefixes.

### Maintenance Notes  
- Monitor AWS announcements (Canvas updates).  
- Update for full automation (boto3 only; deprecate UI).  
- Lessons Learned: Document in 004_SageMaker_Canvas_Integration_Report.md.  

---

**Approval & Next Actions:**  
- Review this spec; iterate if needed (e.g., more UI focus if API automation complex).  
- Implement per Phase 4.  
- Once complete, draft Spec 005 for QuickSight visualization or full end-to-end testing.