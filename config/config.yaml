# config/config.yaml
# Configuration for AWS-CapacityForecaster project
# Use python-dotenv to load sensitive values from .env

project:
  name: AWS-CapacityForecaster
  version: 1.0
  description: Cloud-native enterprise server capacity forecasting system

aws:
  region: us-east-1
  profile: study                          # boto3 profile name (optional)
  bucket_name: sean-capacity-forecast-data
  raw_prefix: raw/server_metrics/
  processed_prefix: processed/server_metrics/
  features_prefix: processed/features/
  sagemaker_role_arn: ""                  # Fill from .env or IAM
  sagemaker_instance_type: ml.t3.medium   # Cheap/small for development
  athena_database: capacity_forecaster_db
  athena_workgroup: primary               # or create custom

data:
  num_servers: 120
  years_of_data: 4
  granularity: daily                      # daily / hourly (future)
  start_date: "2022-01-01"
  end_date: "2025-12-31"
  generated_data_path: data/synthetic/server_metrics.csv.gz  # Centralized output path
  compression: true                       # GZIP compression for S3 efficiency
  metrics: [cpu_p95, mem_p95, disk_p95, net_in_p95, net_out_p95] # Explicit list of metrics to generate
  metadata:
    server_prefix: "SRV-"                 # Prefix for server IDs
    server_id_width: 4                    # Number of digits in server ID
    business_units: ['Retail', 'Investment', 'Wealth', 'Corporate']
    regions: ['us-east-1', 'us-west-2', 'eu-west-1', 'ap-southeast-1']
    criticalities: ['High', 'Medium', 'Low']
    criticality_probs: [0.2, 0.5, 0.3]
  seasonality:
    weekly: true
    weekend_factor: 0.80                  # Multiplier for weekends
    quarterly_peaks: true                 # end-of-quarter banking peaks
    eoq_months: [3, 6, 9, 12]             # Months that end a quarter
    holiday_effect: true
  validation:
    max_missing_pct_warning: 5.0          # Warn if missingness exceeds this %
    row_count_tolerance: 100              # Warn if row count deviates by > N
    min_history_days: 365                 # Minimum history required per server
  samples_count: 200                      # Number of rows to save in sample file
  p95_ranges:
    cpu: [10.0, 95.0]
    memory: [15.0, 92.0]
    disk: [5.0, 85.0]
    network_in: [20.0, 500.0]
    network_out: [10.0, 300.0]

ml:
  forecast_horizon_months: 6
  models:
    - name: Prophet
      enabled: true
      params:
        yearly_seasonality: true
        weekly_seasonality: true
        daily_seasonality: false
        changepoint_prior_scale: 0.05
    - name: RandomForest
      enabled: true
      params:
        n_estimators: 200
        max_depth: 10
        random_state: 42
    - name: GradientBoosting
      enabled: true
      params:
        n_estimators: 150
        learning_rate: 0.05
        max_depth: 6
    - name: AmazonForecast
      enabled: false                        # Optional - toggle on when ready
      forecast_frequency: D
      prediction_length: 180
  evaluation:
    metrics: [MAE, RMSE, MAPE]
    test_split_ratio: 0.2
    cross_validation_folds: 5

feature_engineering:
  lags_days: [1, 3, 7, 14, 30]           # 1-day, weekly, monthly lags
  rolling_windows_days: [7, 30, 90]      # rolling means/std
  impute_method: "linear"                # or "knn", "median", "forward_fill"
  handle_outliers: true                  # Toggle outlier capping
  outlier_z_threshold: 4.0               # flag or cap values > Z from rolling mean
  outlier_window_days: 30                # Window size for rolling Z-score
  encode_metadata: true                  # one-hot business_unit/region/criticality
  metadata_columns: [business_unit, region, criticality] # Columns to one-hot encode
  add_eoq_flag: true                     # binary is_eoq_window
  eoq_window_days: 7                     # Number of days at end of quarter
  add_holiday_flag: true                 # binary is_holiday (US banking)
  add_trend_features: true               # days_since_start, cumulative_cpu etc.
  anomaly_detection:
    z_score_threshold: 3.0
    knn_neighbors: 5

risk_analysis:
  high_risk_threshold: 80.0               # P95 % utilization → flag as risk
  very_high_risk_threshold: 90.0
  underutilized_threshold: 40.0           # Average utilization → candidate for consolidation
  clustering:
    n_clusters: 4                         # K-Means clusters
    features: [cpu_p95, memory_p95, disk_p95]

paths:
  local_data_dir: data/scratch/           # For local testing only
  raw_dir: raw/
  intermediate_dir: intermediate/
  processed_dir: processed/
  summaries_dir: reports/summaries/
  samples_dir: samples/
  reports_dir: reports/
  model_artifacts_dir: models/
  forecasts_dir: forecasts/               # ← added (matches your current usage)
  metrics_dir: metrics/                   # ← added (matches your current usage)
  risk_analysis_dir: risk_analysis/       # ← added for Module 05 outputs

  # ── Added configurable filenames ──
  module_03_summary_filename: module_03_summary.json  # ← used by Module 03
  metrics_summary_filename: model_comparison.json     # ← used by Module 04 for metrics JSON
  forecasts_summary_filename: all_model_forecasts.parquet  # ← used by Module 04 for forecasts Parquet

visualization:
  theme: darkgrid  # seaborn style (compatible with matplotlib 3.8+)
  figure_size: [12, 6]
  interactive: true                       # Use plotly/dash when true
  export_formats: [png, pdf, html]

logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: logs/capacity_forecaster.log

model_training:
  # Core settings
  target_metric: cpu_p95                      # column to forecast (later: mem_p95, disk_p95_write, etc.)
  horizon_days: 90                            # forecast 3 months ahead (Citi typical)
  test_split_date: "2024-01-01"               # fixed date split (or fraction: 0.80)
  min_history_days: 365                       # skip servers with too little data
  forecast_quantiles: [0.05, 0.50, 0.95]      # for uncertainty bands (Prophet + others later)

  # Which models to run (add/remove easily)
  enabled_models:
    - baseline_naive_seasonal
    - prophet
    - random_forest
    # - xgboost           # uncomment when ready
    # - lightgbm

  baseline_naive_seasonal:
    period_days: 7                            # weekly repeating pattern (most servers)

  prophet:
    growth: linear
    yearly_seasonality: true
    weekly_seasonality: true
    daily_seasonality: false
    changepoint_prior_scale: 0.05
    seasonality_prior_scale: 10.0
    holidays_prior_scale: 10.0
    # Which features to use as regressors (must exist in data)
    regressor_columns:
      - is_eoq_window
      - is_holiday
      - is_weekend
      # - quarter
      # month encoded by seasonality usually, but can add explicit
      - cpu_p95_lag_1d
      - cpu_p95_lag_7d
      # Rolling stats are powerful but handle with care in recursive forecasting
      # For direct multi-step, we use them directly. Prophet handles them if we provide future values (we don't have them easily)
      # Simpler V1: Use only calendar regressors for Prophet
      # Advanced V2: Use lagged features but requires recursive loop

  random_forest:
    n_estimators: 150
    max_depth: 12
    min_samples_split: 5
    random_state: 42
    n_jobs: -1                                # use all cores
    features:
      - is_eoq_window
      - is_holiday
      - is_weekend
      - quarter
      - month
      - month_sin
      - month_cos

execution:
  mode: local                             # local | sagemaker_processing | sagemaker_training | lambda
  parallel_workers: 4                     # joblib/multiprocessing
  random_seed: 42